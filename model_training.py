# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iPCdxNr3Udm8yq4rHT87l0lLX_zF8OqU
"""

import tensorflow as tf
from tensorflow.keras import models,layers,callbacks
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow_datasets as tfds

# loading data
(ds_train, ds_test), info = tfds.load(
    "emnist/balanced",
    split=["train", "test"],
    as_supervised=True,
    with_info=True
)

# Segregating data
def dataset(ds):
  images=[]
  labels=[]

  for img,label in ds:
    images.append(img.numpy())
    labels.append(label.numpy())

  return np.array(images),np.array(labels)

X_train,y_train = dataset(ds_train)
X_test,y_test = dataset(ds_test)

# Normalization of Data
X_train = X_train.astype("float32") / 255.0
X_test  = X_test.astype("float32") / 255.0

# Model Architecture Design
model = tf.keras.Sequential([
    # Block 1
    layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3,3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2,2)),
    layers.Dropout(0.25),
    
    # Block 2
    layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2,2)),
    layers.Dropout(0.25),
    
    # Block 3
    layers.Conv2D(128, (3,3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2,2)),
    layers.Dropout(0.25),
    
    # Fully Connected
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    
    layers.Dense(47, activation='softmax')
])

# model compiling
model.compile(
    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=7e-4),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

checkpoint=tf.keras.callbacks.ModelCheckpoint(
    "Digit_recognition.h5",
    monitor='val_accuracy',
    mode='max',
    save_best_only=True
)
# data augmentation,Early stopping and Learning Rate Scheduling for accuracy
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1
)

datagen.fit(X_train,y_train)

lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1,
    min_lr=1e-6
)

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=6,
    restore_best_weights=True
)

train = model.fit(
    datagen.flow(X_train,y_train,batch_size=64),
    epochs=30,
    validation_data=(X_test,y_test),
    verbose=1,
    callbacks=[checkpoint,lr_schedule,early_stop]
)

print(f"\nBest validation accuracy: {max(train.history['val_accuracy']):.4f}")